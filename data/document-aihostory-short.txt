The history of artificial intelligence (AI) began in antiquity, with myths, stories, and rumors of artificial beings endowed with intelligence or consciousness by master craftsmen. The study of logic and formal reasoning from antiquity to the present led directly to the invention of the programmable digital computer in the 1940s, a machine based on abstract mathematical reasoning. This device and the ideas behind it inspired scientists to begin discussing the possibility of building an electronic brain.

The field of AI research was founded at a workshop held on the campus of Dartmouth College in 1956.[1] Attendees of the workshop became the leaders of AI research for decades. Many of them predicted that machines as intelligent as humans would exist within a generation. The U.S. government provided millions of dollars with the hope of making this vision come true.[2]

Eventually, it became obvious that researchers had grossly underestimated the difficulty of this feat.[3] In 1974, criticism from James Lighthill and pressure from the U.S.A. Congress led the U.S. and British Governments to stop funding undirected research into artificial intelligence. Seven years later, a visionary initiative by the Japanese Government and the success of expert systems reinvigorated investment in AI, and by the late 1980s, the industry had grown into a billion-dollar enterprise. However, investors' enthusiasm waned in the 1990s, and the field was criticized in the press and avoided by industry (a period known as an "AI winter"). Nevertheless, research and funding continued to grow under other names.

In the early 2000s, machine learning was applied to a wide range of problems in academia and industry. The success was due to the availability of powerful computer hardware, the collection of immense data sets, and the application of solid mathematical methods. Soon after, deep learning proved to be a breakthrough technology, eclipsing all other methods. The transformer architecture debuted in 2017 and was used to produce impressive generative AI applications, amongst other use cases.

Investment in AI boomed in the 2020s. The recent AI boom, initiated by the development of transformer architecture, led to the rapid scaling and public releases of large language models (LLMs) like ChatGPT. These models exhibit human-like traits of knowledge, attention, and creativity, and have been integrated into various sectors, fueling exponential investment in AI. However, concerns about the potential risks and ethical implications of advanced AI have also emerged, causing debate about the future of AI and its impact on society.

Precursors
Mythical, fictional, and speculative precursors
Myth and legend
In Greek mythology, Talos was a creature made of bronze who acted as a guardian for the island of Crete. He would throw boulders at the ships of invaders and would complete 3 circuits around the island's perimeter daily.[4] According to pseudo-Apollodorus' Bibliotheke, Hephaestus forged Talos with the aid of a cyclops and presented the automaton as a gift to Minos.[5] In the Argonautica, Jason and the Argonauts defeated Talos by removing a plug near his foot, causing the vital ichor to flow out from his body and rendering him lifeless.[6]

Pygmalion was a legendary king and sculptor of Greek mythology, famously represented in Ovid's Metamorphoses. In the 10th book of Ovid's narrative poem, Pygmalion becomes disgusted with women when he witnesses the way in which the Propoetides prostitute themselves. Despite this, he makes offerings at the temple of Venus, asking the goddess to bring to him a woman just like a statue he carved.[7]

Medieval legends of artificial beings

Depiction of a homunculus from Goethe's Faust
In Of the Nature of Things, the Swiss alchemist Paracelsus describes a procedure that he claims can fabricate an "artificial man". By placing the "sperm of a man" in horse dung, and feeding it the "Arcanum of Man's blood" after 40 days, the concoction will become a living infant.[8]

The earliest written account regarding golem-making is found in the writings of Eleazar ben Judah of Worms in the early 13th century.[9] During the Middle Ages, it was believed that the animation of a Golem could be achieved by insertion of a piece of paper with any of God's names on it, into the mouth of the clay figure.[10] Unlike legendary automata like Brazen Heads,[11] a Golem was unable to speak.[12]

Takwin, the artificial creation of life, was a frequent topic of Ismaili alchemical manuscripts, especially those attributed to Jabir ibn Hayyan. Islamic alchemists attempted to create a broad range of life through their work, ranging from plants to animals.[13]

In Faust: The Second Part of the Tragedy by Johann Wolfgang von Goethe, an alchemically fabricated homunculus, destined to live forever in the flask in which he was made, endeavors to be born into a full human body. Upon the initiation of this transformation, however, the flask shatters and the homunculus dies.[14]

Modern fiction
Main article: Artificial intelligence in fiction
By the 19th century, ideas about artificial men and thinking machines became a popular theme in fiction. Notable works like Mary Shelley's Frankenstein and Karel ÄŒapek's R.U.R. (Rossum's Universal Robots)[15] explored the concept of artificial life. Speculative essays, such as Samuel Butler's "Darwin among the Machines",[16] and Edgar Allan Poe's "Maelzel's Chess Player"[17] reflected society's growing interest in machines with artificial intelligence. AI remains a common topic in science fiction today.[18]